import { useState, useEffect } from 'react';
import Head from 'next/head';
import { useLanguage } from '../contexts/LanguageContext';
import LanguageSelector from '../components/LanguageSelector';
import { secureGetItem } from '../lib/secure-storage';

export default function LLMColaborativa() {
  const { t } = useLanguage();
  
  // Estado para autenticaci√≥n
  const [password, setPassword] = useState('');
  const [authenticated, setAuthenticated] = useState(false);
  
  // Estado para el proceso
  const [query, setQuery] = useState('');
  const [processing, setProcessing] = useState(false);
  const [step, setStep] = useState(0);
  const [terminal, setTerminal] = useState([]);
  const [finalResponse, setFinalResponse] = useState('');
  const [metrics, setMetrics] = useState(null);
  const [copied, setCopied] = useState(false);
  const [errors, setErrors] = useState({});
  const [generatingDocs, setGeneratingDocs] = useState(false);
  const [docsGenerated, setDocsGenerated] = useState(false);

  // Estado para estad√≠sticas de tokens
  const [tokenStats, setTokenStats] = useState({
    claude: { usage: { input: 0, output: 0, cost: 0 }, balance: 100 },
    openai: { usage: { input: 0, output: 0, cost: 0 }, balance: 100 },
    gemini: { usage: { input: 0, output: 0, cost: 0 }, balance: 100 },
    perplexity: { usage: { input: 0, output: 0, cost: 0 }, balance: 100 },
    deepseek: { usage: { input: 0, output: 0, cost: 0 }, balance: 100 },
    mistral: { usage: { input: 0, output: 0, cost: 0 }, balance: 100 }
  });

  // Estado para las respuestas individuales
  const [llmResponses, setLlmResponses] = useState({
    claude: null,
    openai: null,
    gemini: null,
    perplexity: null,
    deepseek: null,
    mistral: null
  });

  // Estado para la memoria de conversaci√≥n (excepto Claude)
  const [conversations, setConversations] = useState({
    openai: [],
    gemini: [],
    perplexity: [],
    deepseek: [],
    mistral: []
  });

  // Estado para el historial completo de conversaci√≥n
  const [conversationHistory, setConversationHistory] = useState([]);
  const [isFollowUp, setIsFollowUp] = useState(false);

  // Actualizar estad√≠sticas de tokens cada 5 segundos
  useEffect(() => {
    const interval = setInterval(() => {
      if (authenticated) {
        fetchTokenStats();
      }
    }, 5000);
    return () => clearInterval(interval);
  }, [authenticated, password]);

  // Funci√≥n para obtener estad√≠sticas de tokens
  const fetchTokenStats = async () => {
    try {
      const response = await fetch('/api/token-stats', {
        headers: {
          'x-auth-password': password
        }
      });
      if (response.ok) {
        const data = await response.json();
        setTokenStats(data);
      } else {
        console.error('Error fetching token stats:', response.status, response.statusText);
      }
    } catch (error) {
      console.error('Error fetching token stats:', error);
    }
  };

  // Funci√≥n de autenticaci√≥n
  const handleAuth = async () => {
    try {
      const response = await fetch('/api/admin/auth', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ password })
      });

      if (response.ok) {
        setAuthenticated(true);
        fetchTokenStats();
      } else {
        setErrors({ auth: t('llmC.wrongPassword') });
      }
    } catch (error) {
      setErrors({ auth: t('llmC.wrongPassword') });
    }
  };

  // Logger del terminal con efectos visuales
  const log = (type, msg, llm = null) => {
    const timestamp = new Date().toLocaleTimeString();
    const entry = { 
      type, 
      msg, 
      llm,
      time: timestamp,
      id: Date.now() + Math.random()
    };
    setTerminal(prev => [...prev, entry]);
  };

  // Funci√≥n para llamar a cada API
  const callLLM = async (llmName, message, conversation = [], apiKeys = {}) => {
    const endpoints = {
      claude: '/api/claude-chat',
      openai: '/api/openai-chat',
      gemini: '/api/gemini-chat',
      perplexity: '/api/perplexity-chat',
      deepseek: '/api/deepseek-chat',
      mistral: '/api/mistral-chat'
    };

    const body = llmName === 'claude' 
      ? { message, context: 'general_query', password, apiKey: apiKeys[llmName] }
      : llmName === 'gemini'
      ? { prompt: message, parameters: { temperature: 0.7 }, password, apiKey: apiKeys[llmName] }
      : { message, conversation, password, apiKey: apiKeys[llmName] };

    const response = await fetch(endpoints[llmName], {
      method: 'POST',
      headers: { 
        'Content-Type': 'application/json',
        'x-auth-password': password
      },
      body: JSON.stringify(body)
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || `${llmName} API Error`);
    }

    const data = await response.json();
    
    // Actualizar estad√≠sticas de tokens localmente
    if (data.usage) {
      setTokenStats(prev => ({
        ...prev,
        [llmName]: {
          ...prev[llmName],
          usage: {
            input: prev[llmName].usage.input + data.usage.inputTokens,
            output: prev[llmName].usage.output + data.usage.outputTokens,
            cost: prev[llmName].usage.cost + data.usage.cost
          },
          balance: data.usage.remainingBalance
        }
      }));
    }

    return data;
  };

  // Validaci√≥n de consulta
  const validate = () => {
    const newErrors = {};
    if (query.length < 10) {
      newErrors.query = t('promptBoost.errors.tooShort').replace('prompt', 'consulta');
    }
    
    setErrors(newErrors);
    return Object.keys(newErrors).length === 0;
  };

  // Funci√≥n para obtener API keys del localStorage con encriptaci√≥n segura
  const getApiKeys = async () => {
    const keys = {};
    const providers = ['claude', 'openai', 'gemini', 'perplexity', 'deepseek', 'mistral'];
    const encryptionPassword = password || 'pixan-default-key';

    for (const provider of providers) {
      try {
        const key = await secureGetItem(`pixan_api_${provider}`, encryptionPassword);
        if (key) {
          keys[provider] = key;
        }
      } catch (e) {
        console.error(`Error decrypting ${provider} key:`, e);
      }
    }

    return keys;
  };

  // Proceso principal de colaboraci√≥n
  const startCollaboration = async () => {
    if (!validate()) return;

    setProcessing(true);
    setTerminal([]);
    setFinalResponse('');
    setLlmResponses({ claude: null, openai: null, gemini: null, perplexity: null });
    setMetrics(null);

    const startTime = Date.now();

    // Obtener API keys del localStorage con encriptaci√≥n segura
    const apiKeys = await getApiKeys();

    try {
      // Paso 1: Inicializaci√≥n
      setStep(1);
      log('system', `üöÄ ${t('llmC.terminal.starting')}`);
      log('system', `üìã ${t('llmC.terminal.models')}: CLAUDE, OPENAI, GEMINI, PERPLEXITY`);

      // Paso 2: Claude analiza el prompt y asigna roles
      setStep(2);
      let roleAssignments = {};
      
      log('system', `üß† ${t('llmC.terminal.analyzingQuery')}`);
      log('claude', `üìä ${t('llmC.terminal.analyzingType')}`, 'claude');
      
      const analysisPrompt = `Analiza esta consulta y asigna roles espec√≠ficos a TODOS los LLMs disponibles, incluy√©ndote a ti mismo (Claude):

${isFollowUp && conversationHistory.length > 0 ? `CONTEXTO DE CONVERSACI√ìN PREVIA:
${conversationHistory.map(h => `${h.role}: ${h.content}`).join('\n')}

NUEVA ` : ''}CONSULTA DEL USUARIO: "${query}"

TODOS LOS LLMs DISPONIBLES: CLAUDE, OPENAI, GEMINI, PERPLEXITY

CAPACIDADES DE CADA LLM:
- CLAUDE (T√ö): Razonamiento superior, an√°lisis cr√≠tico, s√≠ntesis conceptual, arquitectura de soluciones, filosof√≠a, √©tica
- GPT-4: An√°lisis profundo, razonamiento complejo, c√≥digo, matem√°ticas, ingenier√≠a
- GEMINI: Creatividad, s√≠ntesis multimodal, perspectivas innovadoras, generaci√≥n de contenido
- PERPLEXITY: B√∫squeda en tiempo real, verificaci√≥n de hechos, informaci√≥n actualizada, investigaci√≥n

INSTRUCCIONES CR√çTICAS:
1. Identifica el tipo de consulta (t√©cnica, creativa, anal√≠tica, investigativa, mixta)
2. As√≠gna-TE A TI MISMO (Claude) un rol espec√≠fico basado en tus fortalezas superiores
3. Asigna a cada LLM restante un rol espec√≠fico basado en sus fortalezas
4. Crea una instrucci√≥n personalizada para cada LLM (incluy√©ndote) que maximice su contribuci√≥n
5. Devuelve la respuesta en formato JSON exactamente as√≠:

{
  "queryType": "tipo de consulta",
  "analysis": "breve an√°lisis de la consulta",
  "roles": {
    "claude": { "role": "t√≠tulo del rol para Claude", "instruction": "instrucci√≥n espec√≠fica para Claude" },
    "openai": { "role": "t√≠tulo del rol", "instruction": "instrucci√≥n espec√≠fica" },
    "gemini": { "role": "t√≠tulo del rol", "instruction": "instrucci√≥n espec√≠fica" },
    "perplexity": { "role": "t√≠tulo del rol", "instruction": "instrucci√≥n espec√≠fica" },
    "deepseek": { "role": "t√≠tulo del rol", "instruction": "instrucci√≥n espec√≠fica" },
    "mistral": { "role": "t√≠tulo del rol", "instruction": "instrucci√≥n espec√≠fica" }
  }
}

IMPORTANTE: 
- Como Claude, as√≠gna-te el rol m√°s estrat√©gico y de mayor valor para esta consulta espec√≠fica
- Tus fortalezas incluyen razonamiento superior, an√°lisis cr√≠tico y s√≠ntesis conceptual
- Adapta todas las instrucciones al contexto espec√≠fico de la consulta`;

      try {
        const analysisResponse = await callLLM('claude', analysisPrompt, [], apiKeys);
        const analysis = JSON.parse(analysisResponse.content);
        roleAssignments = analysis.roles;
        
        log('claude', `‚úÖ ${t('llmC.terminal.analysisComplete')} "${analysis.queryType}"`, 'claude');
        log('system', `üìã ${t('llmC.terminal.roleAssignment')}:`);
        
        // Mostrar roles asignados en formato tabla
        Object.entries(roleAssignments).forEach(([llm, assignment]) => {
          log('system', `‚îÉ ${llm.toUpperCase().padEnd(12)} ‚îÉ ${assignment.role.padEnd(30)} ‚îÉ`);
        });
        
      } catch (error) {
        log('error', `‚ö†Ô∏è ${t('llmC.terminal.error')} an√°lisis de Claude, usando roles gen√©ricos`);
        // Roles por defecto si falla el an√°lisis
        roleAssignments = {
          claude: { role: "Arquitecto de Soluciones", instruction: "Proporciona una perspectiva estrat√©gica y an√°lisis conceptual profundo" },
          openai: { role: "Analista Principal", instruction: "Proporciona un an√°lisis detallado y estructurado" },
          gemini: { role: "Innovador Creativo", instruction: "Aporta perspectivas creativas y soluciones innovadoras" },
          perplexity: { role: "Investigador", instruction: "Busca informaci√≥n actualizada y verifica hechos" },
          deepseek: { role: "Explorador de Soluciones", instruction: "Busca soluciones innovadoras y alternativas no convencionales" },
          mistral: { role: "Especialista T√©cnico", instruction: "Proporciona an√°lisis t√©cnico especializado y recomendaciones" }
        };
      }

      // Paso 3: Env√≠o paralelo a todos los LLMs con sus roles espec√≠ficos
      setStep(3);
      log('system', `‚ö° ${t('llmC.terminal.sendingTasks')}`);
      
      // Incluir Claude en la primera ronda
      const participatingLLMs = ['claude', 'openai', 'gemini', 'perplexity', 'deepseek', 'mistral'];
      
      const llmPromises = participatingLLMs.map(async (llmName) => {
        try {
          const role = roleAssignments[llmName];
          if (!role) return null;
          
          log('system', `‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
          log(llmName, `üé≠ ${t('llmC.terminal.role')}: ${role.role}`, llmName);
          log(llmName, `üìù ${t('llmC.terminal.task')}: ${role.instruction}`, llmName);
          
          // Crear prompt personalizado para cada LLM seg√∫n su rol
          const customPrompt = `${isFollowUp && conversationHistory.length > 0 ? `CONTEXTO DE CONVERSACI√ìN PREVIA:
${conversationHistory.slice(-4).map(h => `${h.role === 'user' ? 'Usuario' : 'Asistente'}: ${h.content.substring(0, 500)}${h.content.length > 500 ? '...' : ''}`).join('\n\n')}

` : ''}${role.instruction}

${isFollowUp ? 'NUEVA ' : ''}CONSULTA ${isFollowUp ? 'DE SEGUIMIENTO' : 'ORIGINAL'}: ${query}

Por favor, responde seg√∫n tu rol asignado de "${role.role}" y enf√≥cate en ${role.instruction.toLowerCase()}${isFollowUp ? ', considerando el contexto de la conversaci√≥n previa' : ''}.`;
          
          const conversation = conversations[llmName] || [];
          const response = await callLLM(llmName, customPrompt, conversation, apiKeys);
          
          // Actualizar memoria para LLMs que la soportan
          if (llmName !== 'claude') {
            setConversations(prev => ({
              ...prev,
              [llmName]: [...conversation, 
                { role: 'user', content: customPrompt },
                { role: 'assistant', content: response.content }
              ]
            }));
          }
          
          log(llmName, `‚úÖ ${t('llmC.terminal.responseReceived')} (${response.content.length} ${t('llmC.terminal.characters')})`, llmName);
          log('system', `‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ`);
          
          return { 
            llm: llmName, 
            response: response.content, 
            role: role.role,
            success: true 
          };
        } catch (error) {
          log('error', `‚ùå ${t('llmC.terminal.error')} ${llmName.toUpperCase()}: ${error.message}`, llmName);
          return { llm: llmName, error: error.message, success: false };
        }
      }).filter(p => p !== null);

      // Paso 4: Esperar respuestas especializadas
      setStep(4);
      const results = await Promise.all(llmPromises);
      const successfulResults = results.filter(r => r && r.success);
      
      // Actualizar estado con respuestas
      const newResponses = {};
      successfulResults.forEach(result => {
        newResponses[result.llm] = result.response;
      });
      setLlmResponses(newResponses);

      log('system', `‚úÖ ${t('llmC.terminal.successfulResponses')} ${successfulResults.length}`);

      if (successfulResults.length === 0) {
        throw new Error(t('llmC.terminal.noResponses'));
      }

      // Paso 5: Consolidaci√≥n con Claude
      setStep(5);
      
      // Variable para almacenar la respuesta final fuera de los bloques
      let currentFinalResponse = '';
      
      // Separar la respuesta de Claude de las dem√°s
      const claudeResponse = successfulResults.find(r => r.llm === 'claude');
      const otherResponses = successfulResults.filter(r => r.llm !== 'claude');
      
      if (successfulResults.length > 1) {
        log('system', `üß† ${t('llmC.terminal.consolidating')}`);
        
        let consolidationQuery;
        
        if (claudeResponse && otherResponses.length > 0) {
          // Claude particip√≥ y hay otras respuestas para consolidar
          consolidationQuery = `Como Director de Orquesta de IA, ahora debes consolidar TODAS las respuestas (incluyendo tu propia respuesta inicial) en una s√≠ntesis magistral final.

${isFollowUp && conversationHistory.length > 0 ? `üìö **CONTEXTO DE CONVERSACI√ìN:**
${conversationHistory.slice(-4).map(h => `${h.role === 'user' ? 'üë§ Usuario' : 'ü§ñ Asistente'}: ${h.content.substring(0, 300)}${h.content.length > 300 ? '...' : ''}`).join('\n')}

` : ''}üìã **${isFollowUp ? 'NUEVA ' : ''}CONSULTA${isFollowUp ? ' DE SEGUIMIENTO' : ' ORIGINAL'}:** "${query}"

üé≠ **TU PROPIA RESPUESTA INICIAL:**
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
ü§ñ **CLAUDE** - ${claudeResponse.role}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
${claudeResponse.response}

üé≠ **RESPUESTAS DE OTROS LLMs:**
${otherResponses.map((result, idx) => 
  `\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
ü§ñ **${result.llm.toUpperCase()}** - ${result.role}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
${result.response}`
).join('\n')}

üìä **INSTRUCCIONES DE CONSOLIDACI√ìN ESPECIAL:**

Ahora debes actuar como un meta-analista que eval√∫a su propia contribuci√≥n junto con las de otros expertos:

1. **EVALUACI√ìN CR√çTICA:**
   - Analiza objetivamente tu propia respuesta inicial junto con las dem√°s
   - Identifica fortalezas y debilidades en todas las perspectivas (incluyendo la tuya)
   - Busca complementariedades entre tu enfoque y los otros

2. **S√çNTESIS MEJORADA:**
   - Combina lo mejor de tu perspectiva inicial con los insights de otros LLMs
   - Corrige cualquier sesgo o limitaci√≥n identificada en tu respuesta inicial
   - Aprovecha las fortalezas √∫nicas de cada contribuci√≥n`
        } else {
          // Consolidaci√≥n est√°ndar sin Claude participando
          consolidationQuery = `Como Director de Orquesta de IA, consolida estas respuestas especializadas en una s√≠ntesis magistral.

${isFollowUp && conversationHistory.length > 0 ? `üìö **CONTEXTO DE CONVERSACI√ìN:**
${conversationHistory.slice(-4).map(h => `${h.role === 'user' ? 'üë§ Usuario' : 'ü§ñ Asistente'}: ${h.content.substring(0, 300)}${h.content.length > 300 ? '...' : ''}`).join('\n')}

` : ''}üìã **${isFollowUp ? 'NUEVA ' : ''}CONSULTA${isFollowUp ? ' DE SEGUIMIENTO' : ' ORIGINAL'}:** "${query}"

üé≠ **RESPUESTAS POR ROL:**
${successfulResults.map((result, idx) => 
  `\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
ü§ñ **${result.llm.toUpperCase()}** - ${result.role}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
${result.response}`
).join('\n')}`
        }
        
        // Agregar instrucciones comunes de formato visual
        consolidationQuery += `

üìä **INSTRUCCIONES DE FORMATO:**

Tu respuesta DEBE incluir estos elementos gr√°ficos:

1. **ESTRUCTURA VISUAL:**
   - Usa encabezados con emojis tem√°ticos (üìä, üéØ, üí°, üîç, ‚ö°)
   - Separa secciones con l√≠neas: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   - Destaca puntos clave con **negrita** y *cursiva*

2. **TABLAS COMPARATIVAS** (cuando aplique):
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Aspecto     ‚îÇ Opci√≥n A     ‚îÇ Opci√≥n B     ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ Ejemplo     ‚îÇ Valor 1      ‚îÇ Valor 2      ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

3. **LISTAS JER√ÅRQUICAS:**
   ‚Ä¢ Punto principal
     ‚ó¶ Subpunto con detalle
       ‚ñ™ Detalle espec√≠fico

4. **INDICADORES VISUALES:**
   ‚úÖ Informaci√≥n verificada por m√∫ltiples fuentes
   ‚ö†Ô∏è Puntos de atenci√≥n o precauci√≥n
   üí° Insights √∫nicos o innovadores
   üéØ Conclusiones clave
   üìà Tendencias o patrones

5. **BLOQUES DESTACADOS:**
   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
   ‚ïë  PUNTO CLAVE: Texto importante     ‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

IMPORTANTE: Presenta una s√≠ntesis visualmente rica que combine lo mejor de todas las perspectivas.`;

        const consolidationResponse = await callLLM('claude', consolidationQuery, [], apiKeys);
        
        setStep(6);
        log('system', '‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        log('claude', `üéØ ${t('llmC.consolidatedResponse')}:`, 'claude');
        log('system', '‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        log('claude', consolidationResponse.content, 'claude');
        log('system', '‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        currentFinalResponse = consolidationResponse.content;
        setFinalResponse(currentFinalResponse);
        
        log('system', `‚ú® ${t('llmC.terminal.consolidationComplete')}`);
      } else if (successfulResults.length === 1) {
        // Solo un LLM respondi√≥
        currentFinalResponse = successfulResults[0].response;
        setFinalResponse(currentFinalResponse);
        log('system', `‚ú® Respuesta √∫nica de ${successfulResults[0].llm.toUpperCase()}`);
      } else {
        // M√∫ltiples respuestas pero sin Claude para consolidar
        currentFinalResponse = successfulResults.map((result, idx) => 
          `**${result.llm.toUpperCase()}:**\n${result.response}`
        ).join('\n\n---\n\n');
        
        setFinalResponse(currentFinalResponse);
        log('system', 'üìä M√∫ltiples respuestas presentadas sin consolidaci√≥n');
      }

      // Paso 6: Calcular m√©tricas
      setStep(6);
      log('system', `üìà ${t('llmC.terminal.calculatingMetrics')}`);
      
      const processingTime = Math.round((Date.now() - startTime) / 1000);
      const calculatedMetrics = {
        llmsUsed: successfulResults.length,
        totalLlmsAvailable: 4,
        processingTime,
        consolidationUsed: successfulResults.length > 1,
        memoryEnabled: 3, // OpenAI, Gemini, Perplexity tienen memoria
        responseLengths: successfulResults.map(r => r.response.length)
      };
      
      setMetrics(calculatedMetrics);
      log('system', `üèÜ ${t('llmC.terminal.collaborationSuccess')}`);
      
      // Guardar en el historial de conversaci√≥n
      const newHistory = [
        ...conversationHistory,
        { role: 'user', content: query },
        { role: 'assistant', content: currentFinalResponse || '' }
      ];
      setConversationHistory(newHistory);
      setIsFollowUp(true);
      
      // Limpiar el input para permitir nueva pregunta
      setQuery('');

    } catch (error) {
      log('error', `üí• ${t('llmC.terminal.criticalError')}: ${error.message}`);
    } finally {
      setProcessing(false);
      setStep(0);
    }
  };

  // Funci√≥n para copiar respuesta
  const copyResponse = () => {
    navigator.clipboard.writeText(finalResponse);
    setCopied(true);
    setTimeout(() => setCopied(false), 2000);
  };

  // Funci√≥n para cancelar proceso
  const cancelProcess = () => {
    setProcessing(false);
    setStep(0);
    log('system', `‚èπÔ∏è ${t('llmC.terminal.processCanceled')}`);
  };

  // Funci√≥n para limpiar memoria
  const clearMemory = () => {
    setConversations({ openai: [], gemini: [], perplexity: [], deepseek: [], mistral: [] });
    setConversationHistory([]);
    setIsFollowUp(false);
    setFinalResponse('');
    setTerminal([]);
    log('system', `üßπ ${t('llmC.terminal.memoryCleared')}`);
  };

  // Funci√≥n para generar Google Docs con Gemini
  const generateGoogleDocs = async () => {
    if (!finalResponse) {
      return;
    }

    setGeneratingDocs(true);
    log('system', `üìÑ Gemini iniciando generaci√≥n de ${t('llmC.googleDocs')}...`);

    try {
      const queryType = query.toLowerCase().includes('an√°lisis') ? 'anal√≠tica' :
                       query.toLowerCase().includes('crear') || query.toLowerCase().includes('dise√±') ? 'creativa' :
                       query.toLowerCase().includes('investig') || query.toLowerCase().includes('estudi') ? 'investigaci√≥n' :
                       query.toLowerCase().includes('c√≥digo') || query.toLowerCase().includes('t√©cnic') ? 't√©cnica' : 'general';

      const response = await fetch('/api/generate-docs', {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json',
          'x-auth-password': password
        },
        body: JSON.stringify({
          content: finalResponse,
          title: `An√°lisis Multi-IA: ${query.substring(0, 50)}...`,
          queryType,
          password
        })
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error || 'Error generando documento');
      }

      const data = await response.json();
      
      // Crear y descargar el archivo HTML
      const blob = new Blob([data.htmlContent], { type: 'text/html' });
      const url = window.URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = data.fileName;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      window.URL.revokeObjectURL(url);

      setDocsGenerated(true);
      log('gemini', `üìÑ Documento HTML generado: ${data.fileName}`, 'gemini');
      log('system', `‚úÖ Documento listo para importar a ${t('llmC.googleDocs')}`);
      
      setTimeout(() => setDocsGenerated(false), 3000);

    } catch (error) {
      log('error', `‚ùå Error generando documento: ${error.message}`);
    } finally {
      setGeneratingDocs(false);
    }
  };

  // Si no est√° autenticado, mostrar pantalla de login
  if (!authenticated) {
    return (
      <>
        <Head>
          <title>LLM Colaborativa - Autenticaci√≥n | Pixan.ai</title>
          <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet" />
        </Head>

        <div className="min-h-screen bg-gradient-to-br from-purple-50 to-cyan-50 flex items-center justify-center">
          <div className="bg-white rounded-xl shadow-2xl p-8 max-w-md w-full">
            <div className="text-center mb-8">
              <h1 className="text-3xl font-bold bg-gradient-to-r from-purple-600 to-cyan-500 bg-clip-text text-transparent">
                LLM Colaborativa
              </h1>
              <p className="text-gray-600 mt-2">{t('llmC.subtitle')}</p>
            </div>

            <div className="space-y-4">
              <input
                type="password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
                onKeyPress={(e) => e.key === 'Enter' && handleAuth()}
                className="w-full px-4 py-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-purple-500 focus:border-transparent"
                placeholder={t('llmC.password')}
                autoFocus
              />
              
              {errors.auth && (
                <p className="text-red-500 text-sm">{errors.auth}</p>
              )}

              <button
                onClick={handleAuth}
                className="w-full py-3 px-6 text-white font-medium rounded-lg bg-gradient-to-r from-purple-600 to-cyan-500 hover:from-purple-700 hover:to-cyan-600 transition-all duration-200"
              >
                {t('llmC.access')}
              </button>
            </div>
          </div>
        </div>
      </>
    );
  }

  return (
      <>
        <Head>
        <title>LLM Colaborativa - IA Multi-Modelo | Pixan.ai</title>
        <meta name="description" content="Colaboraci√≥n inteligente entre Claude, GPT-4, Gemini y Perplexity con consolidaci√≥n autom√°tica - Desarrollado por Pixan.ai" />
        <link rel="icon" href="/favicon.ico" />
        <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet" />
      </Head>

      <style jsx global>{`
        * {
          margin: 0;
          padding: 0;
          box-sizing: border-box;
        }

        body {
          font-family: 'Inter', sans-serif;
          background: #ffffff;
          color: #000000;
          line-height: 1.6;
        }

        .terminal-glow {
          box-shadow: 0 0 20px rgba(139, 92, 246, 0.3);
        }

        .llm-badge {
          display: inline-block;
          padding: 2px 8px;
          border-radius: 12px;
          font-size: 10px;
          font-weight: 600;
          text-transform: uppercase;
          margin-right: 8px;
        }

        .claude-badge { background: #8b5cf6; color: white; }
        .openai-badge { background: #10b981; color: white; }
        .gemini-badge { background: #3b82f6; color: white; }
        .perplexity-badge { background: #f59e0b; color: white; }
        .deepseek-badge { background: #06b6d4; color: white; }
        .mistral-badge { background: #ef4444; color: white; }
        .system-badge { background: #6b7280; color: white; }
        .error-badge { background: #ef4444; color: white; }

        @keyframes pulse-glow {
          0%, 100% { box-shadow: 0 0 5px rgba(139, 92, 246, 0.5); }
          50% { box-shadow: 0 0 20px rgba(139, 92, 246, 0.8); }
        }

        .processing-glow {
          animation: pulse-glow 2s infinite;
        }

        .token-monitor {
          position: fixed;
          top: 20px;
          right: 20px;
          background: rgba(255, 255, 255, 0.95);
          backdrop-filter: blur(10px);
          border-radius: 12px;
          padding: 16px;
          box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
          z-index: 100;
          min-width: 300px;
        }

        @media (max-width: 768px) {
          .token-monitor {
            position: relative;
            top: auto;
            right: auto;
            margin-bottom: 20px;
          }
        }
      `}</style>

      <div className="min-h-screen bg-white">
        {/* Monitor de Tokens */}
        <div className="token-monitor">
          <h3 className="text-sm font-semibold text-gray-700 mb-3">üí∞ Monitor de Tokens y Saldos</h3>
          <div className="space-y-2">
            {Object.entries(tokenStats).map(([llm, stats]) => (
              <div key={llm} className="flex justify-between items-center text-xs">
                <span className={`${llm}-badge`}>{llm.toUpperCase()}</span>
                <div className="flex gap-3">
                  <span className="text-gray-600">
                    {stats.usage.input + stats.usage.output} tokens
                  </span>
                  <span className="text-gray-900 font-medium">
                    ${stats.usage.cost.toFixed(4)}
                  </span>
                  <span className={`font-bold ${stats.balance < 10 ? 'text-red-600' : 'text-green-600'}`}>
                    ${stats.balance.toFixed(2)}
                  </span>
                </div>
              </div>
            ))}
          </div>
        </div>

        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12">
          {/* Language Selector */}
          <div className="flex justify-end mb-6">
            <LanguageSelector />
          </div>
          
          {/* Header */}
          <div className="text-center mb-12">
            <div className="flex justify-center mb-6">
              <svg width="163" height="47" viewBox="0 0 163 47" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M0 12H3.49722V37.18H0V12Z" fill="#28106A"/>
                <path d="M14.9681 12H18.6612V30.3045H14.9681V12Z" fill="#D34C54"/>
                <path d="M7.27422 12H10.9673V30.3045H7.27422V12Z" fill="#28106A"/>
                <path d="M45.4261 46.8182V10.8182H50.4034V15.0625H50.8295C51.125 14.517 51.5511 13.8864 52.108 13.1705C52.6648 12.4545 53.4375 11.8295 54.4261 11.2955C55.4148 10.75 56.7216 10.4773 58.3466 10.4773C60.4602 10.4773 62.3466 11.0114 64.0057 12.0795C65.6648 13.1477 66.9659 14.6875 67.9091 16.6989C68.8636 18.7102 69.3409 21.1307 69.3409 23.9602C69.3409 26.7898 68.8693 29.2159 67.9261 31.2386C66.983 33.25 65.6875 34.8011 64.0398 35.892C62.392 36.9716 60.5114 37.5114 58.3977 37.5114C56.8068 37.5114 55.5057 37.2443 54.4943 36.7102C53.4943 36.1761 52.7102 35.5511 52.142 34.8352C51.5739 34.1193 51.1364 33.483 50.8295 32.9261H50.5227V46.8182H45.4261ZM50.4205 23.9091C50.4205 25.75 50.6875 27.3636 51.2216 28.75C51.7557 30.1364 52.5284 31.2216 53.5398 32.0057C54.5511 32.7784 55.7898 33.1648 57.2557 33.1648C58.7784 33.1648 60.0511 32.7614 61.0739 31.9545C62.0966 31.1364 62.8693 30.0284 63.392 28.6307C63.9261 27.233 64.1932 25.6591 64.1932 23.9091C64.1932 22.1818 63.9318 20.6307 63.4091 19.2557C62.8977 17.8807 62.125 16.7955 61.0909 16C60.0682 15.2045 58.7898 14.8068 57.2557 14.8068C55.7784 14.8068 54.5284 15.1875 53.5057 15.9489C52.4943 16.7102 51.7273 17.7727 51.2045 19.1364C50.6818 20.5 50.4205 22.0909 50.4205 23.9091Z" fill="#28106A"/>
                <path d="M75.0511 37V10.8182H80.1477V37H75.0511ZM77.625 6.77841C76.7386 6.77841 75.9773 6.48295 75.3409 5.89204C74.7159 5.28977 74.4034 4.57386 74.4034 3.74432C74.4034 2.90341 74.7159 2.1875 75.3409 1.59659C75.9773 0.994317 76.7386 0.693181 77.625 0.693181C78.5114 0.693181 79.267 0.994317 79.892 1.59659C80.5284 2.1875 80.8466 2.90341 80.8466 3.74432C80.8466 4.57386 80.5284 5.28977 79.892 5.89204C79.267 6.48295 78.5114 6.77841 77.625 6.77841Z" fill="#28106A"/>
                <path d="M91.027 10.8182L96.8054 21.0114L102.635 10.8182H108.209L100.044 23.9091L108.277 37H102.703L96.8054 27.2159L90.9247 37H85.3338L93.4815 23.9091L85.4361 10.8182H91.027Z" fill="#28106A"/>
                <path d="M121.014 37.5795C119.355 37.5795 117.855 37.2727 116.514 36.6591C115.173 36.0341 114.111 35.1307 113.327 33.9489C112.554 32.767 112.168 31.3182 112.168 29.6023C112.168 28.125 112.452 26.9091 113.02 25.9545C113.588 25 114.355 24.2443 115.321 23.6875C116.287 23.1307 117.366 22.7102 118.56 22.4261C119.753 22.142 120.969 21.9261 122.207 21.7784C123.776 21.5966 125.048 21.4489 126.026 21.3352C127.003 21.2102 127.713 21.0114 128.156 20.7386C128.599 20.4659 128.821 20.0227 128.821 19.4091V19.2898C128.821 17.8011 128.401 16.6477 127.56 15.8295C126.73 15.0114 125.491 14.6023 123.844 14.6023C122.128 14.6023 120.776 14.983 119.787 15.7443C118.81 16.4943 118.134 17.3295 117.759 18.25L112.969 17.1591C113.537 15.5682 114.366 14.2841 115.457 13.3068C116.56 12.3182 117.827 11.6023 119.259 11.1591C120.69 10.7045 122.196 10.4773 123.776 10.4773C124.821 10.4773 125.929 10.6023 127.099 10.8523C128.281 11.0909 129.384 11.5341 130.406 12.1818C131.44 12.8295 132.287 13.7557 132.946 14.9602C133.605 16.1534 133.935 17.7045 133.935 19.6136V37H128.957V33.4205H128.753C128.423 34.0795 127.929 34.7273 127.27 35.3636C126.611 36 125.764 36.5284 124.73 36.9489C123.696 37.3693 122.457 37.5795 121.014 37.5795ZM122.122 33.4886C123.531 33.4886 124.736 33.2102 125.736 32.6534C126.747 32.0966 127.514 31.3693 128.037 30.4716C128.571 29.5625 128.838 28.5909 128.838 27.5568V24.1818C128.656 24.3636 128.304 24.5341 127.781 24.6932C127.27 24.8409 126.685 24.9716 126.026 25.0852C125.366 25.1875 124.724 25.2841 124.099 25.375C123.474 25.4545 122.952 25.5227 122.531 25.5795C121.543 25.7045 120.639 25.9148 119.821 26.2102C119.014 26.5057 118.366 26.9318 117.878 27.4886C117.401 28.0341 117.162 28.7614 117.162 29.6705C117.162 30.9318 117.628 31.8864 118.56 32.5341C119.491 33.1705 120.679 33.4886 122.122 33.4886Z" fill="#28106A"/>
                <path d="M145.82 21.4545V37H140.723V10.8182H145.615V15.0795H145.939C146.541 13.6932 147.484 12.5795 148.768 11.7386C150.064 10.8977 151.695 10.4773 153.661 10.4773C155.445 10.4773 157.007 10.8523 158.348 11.6023C159.689 12.3409 160.729 13.4432 161.467 14.9091C162.206 16.375 162.575 18.1875 162.575 20.3466V37H157.479V20.9602C157.479 19.0625 156.984 17.5795 155.996 16.5114C155.007 15.4318 153.649 14.892 151.922 14.892C150.74 14.892 149.689 15.1477 148.768 15.6591C147.859 16.1705 147.138 16.9205 146.604 17.9091C146.081 18.8864 145.82 20.0682 145.82 21.4545Z" fill="#28106A"/>
                <path d="M140.7 10.82H145.98V36.99H140.7V10.82Z" fill="#D34C54"/>
              </svg>
            </div>
            <h1 className="text-4xl md:text-5xl font-bold mb-4">
              <span className="bg-gradient-to-r from-purple-600 to-cyan-500 bg-clip-text text-transparent">
                {t('llmC.title')}
              </span>
            </h1>
            <p className="text-xl text-gray-600 max-w-2xl mx-auto">
              Claude dirige y participa: Se asigna un rol, coordina la orquesta de IAs y consolida respuestas con formato visual
            </p>
            <p className="text-sm text-gray-500 mt-2">
              Tecnolog√≠a revolucionaria de colaboraci√≥n multi-IA por Pixan.ai üß†
            </p>
          </div>

          <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
            {/* Formulario */}
            <div className="space-y-6">
              <div className="bg-gray-50 rounded-lg p-6">
                <h2 className="text-xl font-semibold text-gray-800 mb-4">Configuraci√≥n Multi-LLM</h2>
                
                <div className="space-y-6">
                  {/* Consulta */}
                  <div>
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                      {t('llmC.yourQuery')} ({query.length} {t('llmC.charactersCount')})
                    </label>
                    <textarea
                      value={query}
                      onChange={(e) => setQuery(e.target.value)}
                      className="w-full px-4 py-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-purple-500 focus:border-transparent resize-none"
                      rows={4}
                      placeholder={t('llmC.placeholder')}
                      disabled={processing}
                    />
                    {errors.query && (
                      <span className="text-sm text-red-500 mt-1">{errors.query}</span>
                    )}
                  </div>

                  {/* Estado de APIs */}
                  <div className="bg-white rounded-lg p-4">
                    <h4 className="font-medium text-gray-700 mb-2">{t('llmC.connectionStatus')}</h4>
                    <div className="flex flex-wrap gap-2">
                      {Object.keys(tokenStats).map(llm => {
                        const llmData = tokenStats[llm];
                        if (!llmData || typeof llmData.balance === 'undefined') return null;
                        
                        return (
                          <span 
                            key={llm}
                            className={`px-3 py-1 rounded-full text-xs font-medium ${
                              llmData.balance > 0 ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
                            }`}
                          >
                            {llm.toUpperCase()}: {llmData.balance > 0 ? `‚úì ${t('llmC.active')}` : `‚úó ${t('llmC.noBalance')}`}
                          </span>
                        );
                      })}
                    </div>
                  </div>

                  {errors.general && (
                    <div className="text-sm text-red-500 bg-red-50 p-3 rounded-lg">
                      {errors.general}
                    </div>
                  )}

                  {/* Botones */}
                  <button
                    onClick={startCollaboration}
                    disabled={processing}
                    className={`w-full py-4 px-6 text-white font-medium rounded-lg transition-all duration-200 ${
                      processing 
                        ? 'bg-gray-400 cursor-not-allowed' 
                        : 'bg-gradient-to-r from-purple-600 to-cyan-500 hover:from-purple-700 hover:to-cyan-600 processing-glow'
                    }`}
                  >
                    {processing ? (
                      <span className="flex items-center justify-center">
                        üß† {step === 1 ? t('llmC.processing.initializing') : 
                           step === 2 ? t('llmC.processing.analyzing') :
                           step === 3 ? t('llmC.processing.assigning') :
                           step === 4 ? t('llmC.processing.waiting') :
                           step === 5 ? t('llmC.processing.consolidating') :
                           t('llmC.processing.calculating')} ({step}/6)
                      </span>
                    ) : (
                      `üöÄ ${t('llmC.startButton')}`
                    )}
                  </button>

                  {processing && (
                    <button
                      onClick={cancelProcess}
                      className="w-full py-3 px-6 text-gray-700 font-medium rounded-lg border border-gray-300 hover:bg-gray-50 transition-all duration-200"
                    >
                      ‚èπÔ∏è {t('llmC.cancel')}
                    </button>
                  )}

                  <div className="flex gap-2">
                    <button
                      onClick={clearMemory}
                      disabled={processing}
                      className="flex-1 py-2 px-4 text-sm text-gray-600 border border-gray-300 rounded-lg hover:bg-gray-50 transition-all duration-200"
                    >
                      üßπ Limpiar Memoria
                    </button>
                  </div>
                </div>
              </div>
            </div>

            {/* Terminal */}
            <div className="space-y-6">
              <div className={`bg-gray-900 rounded-lg overflow-hidden ${processing ? 'terminal-glow' : ''}`}>
                <div className="bg-gray-800 px-4 py-2 flex items-center justify-between">
                  <div className="flex space-x-2">
                    <div className="w-3 h-3 bg-red-500 rounded-full"></div>
                    <div className="w-3 h-3 bg-yellow-500 rounded-full"></div>
                    <div className="w-3 h-3 bg-green-500 rounded-full"></div>
                  </div>
                  <div className="flex items-center text-gray-400 text-sm">
                    üß† Colaboraci√≥n Multi-IA - Pixan.ai
                  </div>
                </div>
                
                <div className="h-[700px] overflow-y-auto p-4 font-mono text-sm">
                  {terminal.map((log, idx) => (
                    <div key={log.id} className="mb-4">
                      <div className="flex items-center mb-1">
                        <span className={`llm-badge ${log.type}-badge`}>
                          {log.type.toUpperCase()}
                        </span>
                        <span className="text-gray-400 text-xs">
                          [{log.time}]
                        </span>
                      </div>
                      <div className="text-gray-300 whitespace-pre-wrap pl-4 leading-relaxed">
                        {log.msg}
                      </div>
                    </div>
                  ))}
                  
                  {processing && (
                    <div className="flex items-center text-gray-400">
                      <div className="animate-pulse text-purple-400">üß† Procesando...</div>
                    </div>
                  )}
                </div>
              </div>
            </div>
          </div>

          {/* Respuesta Final */}
          {finalResponse && (
            <div className="mt-8 space-y-6">
              <div className="bg-gradient-to-r from-purple-50 to-cyan-50 rounded-lg p-6">
                <div className="flex justify-between items-start mb-4">
                  <h3 className="text-xl font-semibold text-gray-800">{t('llmC.consolidatedResponse')}</h3>
                  <div className="flex gap-2">
                    <button
                      onClick={copyResponse}
                      className="flex items-center px-4 py-2 text-sm bg-white rounded-lg shadow hover:shadow-md transition-shadow"
                    >
                      {copied ? (
                        <>
                          <span className="mr-2 text-green-500">‚úì</span>
                          {t('llmC.copied')}
                        </>
                      ) : (
                        <>
                          <span className="mr-2">üìã</span>
                          {t('llmC.copy')}
                        </>
                      )}
                    </button>
                    
                    <button
                      onClick={generateGoogleDocs}
                      disabled={generatingDocs}
                      className={`flex items-center px-4 py-2 text-sm rounded-lg shadow hover:shadow-md transition-all ${
                        generatingDocs 
                          ? 'bg-gray-400 text-white cursor-not-allowed' 
                          : docsGenerated
                          ? 'bg-green-500 text-white'
                          : 'bg-blue-500 text-white hover:bg-blue-600'
                      }`}
                    >
                      {generatingDocs ? (
                        <>
                          <span className="mr-2 animate-spin">‚öôÔ∏è</span>
                          {t('llmC.generating')}
                        </>
                      ) : docsGenerated ? (
                        <>
                          <span className="mr-2">‚úÖ</span>
                          {t('llmC.downloaded')}
                        </>
                      ) : (
                        <>
                          <span className="mr-2">üìÑ</span>
                          {t('llmC.googleDocs')}
                        </>
                      )}
                    </button>
                  </div>
                </div>
                
                <div className="bg-white rounded-lg p-6 shadow-inner">
                  {/* Historial de conversaci√≥n */}
                  {conversationHistory.length > 0 && (
                    <div className="mb-6 pb-6 border-b border-gray-200">
                      <h4 className="text-sm font-semibold text-gray-600 mb-3 flex items-center">
                        <span className="mr-2">üí¨</span> {t('llmC.conversationHistory')}
                      </h4>
                      <div className="space-y-3 max-h-96 overflow-y-auto">
                        {conversationHistory.slice(-6).map((msg, idx) => (
                          <div key={idx} className={`text-sm ${msg.role === 'user' ? 'text-blue-700' : 'text-gray-700'}`}>
                            <span className="font-semibold">
                              {msg.role === 'user' ? `üë§ ${t('llmC.you')}: ` : `ü§ñ ${t('llmC.assistant')}: `}
                            </span>
                            <span className="whitespace-pre-wrap">
                              {msg.content.substring(0, 200)}{msg.content.length > 200 ? '...' : ''}
                            </span>
                          </div>
                        ))}
                      </div>
                    </div>
                  )}
                  
                  {/* Respuesta actual */}
                  <div className="text-gray-800 whitespace-pre-wrap leading-relaxed">
                    {finalResponse}
                  </div>
                </div>
                
                {/* Input para pregunta de seguimiento */}
                {isFollowUp && (
                  <div className="mt-6 bg-gradient-to-r from-purple-50 to-cyan-50 rounded-lg p-4">
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                      üí≠ {t('llmC.followUp.title')}
                    </label>
                    <div className="flex gap-2">
                      <textarea
                        value={query}
                        onChange={(e) => setQuery(e.target.value)}
                        className="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-purple-500 focus:border-transparent resize-none"
                        rows={2}
                        placeholder={t('llmC.followUp.placeholder')}
                        disabled={processing}
                        onKeyDown={(e) => {
                          if (e.key === 'Enter' && e.ctrlKey && !processing) {
                            startCollaboration();
                          }
                        }}
                      />
                      <div className="flex flex-col gap-2">
                        <button
                          onClick={startCollaboration}
                          disabled={processing || query.length < 10}
                          className={`px-4 py-2 text-white font-medium rounded-lg transition-all ${
                            processing || query.length < 10
                              ? 'bg-gray-400 cursor-not-allowed'
                              : 'bg-gradient-to-r from-purple-600 to-cyan-500 hover:from-purple-700 hover:to-cyan-600'
                          }`}
                        >
                          {processing ? '‚è≥' : 'üöÄ'} {t('llmC.followUp.send')}
                        </button>
                        <button
                          onClick={clearMemory}
                          className="px-4 py-2 bg-red-500 text-white font-medium rounded-lg hover:bg-red-600 transition-all"
                          title="Nueva conversaci√≥n"
                        >
                          üîÑ {t('llmC.followUp.newConversation')}
                        </button>
                      </div>
                    </div>
                    <div className="mt-2 text-xs text-gray-500">
                      {t('llmC.followUp.hint')}
                    </div>
                  </div>
                )}
              </div>

              {/* M√©tricas de Colaboraci√≥n */}
              {metrics && (
                <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
                  <div className="bg-white rounded-lg p-4 shadow">
                    <div className="text-2xl font-bold text-purple-600">{metrics.llmsUsed}/{metrics.totalLlmsAvailable}</div>
                    <div className="text-sm text-gray-600">{t('llmC.metrics.activeLLMs')}</div>
                  </div>
                  <div className="bg-white rounded-lg p-4 shadow">
                    <div className="text-2xl font-bold text-cyan-600">{metrics.processingTime}s</div>
                    <div className="text-sm text-gray-600">{t('llmC.metrics.totalTime')}</div>
                  </div>
                  <div className="bg-white rounded-lg p-4 shadow">
                    <div className="text-2xl font-bold text-green-600">{metrics.consolidationUsed ? '‚úì' : '‚óã'}</div>
                    <div className="text-sm text-gray-600">{t('llmC.metrics.consolidation')}</div>
                  </div>
                  <div className="bg-white rounded-lg p-4 shadow">
                    <div className="text-2xl font-bold text-orange-600">{metrics.memoryEnabled}</div>
                    <div className="text-sm text-gray-600">{t('llmC.metrics.withMemory')}</div>
                  </div>
                </div>
              )}
            </div>
          )}

          {/* Explicaci√≥n de la Tecnolog√≠a */}
          <div className="mt-16 max-w-4xl mx-auto">
            <div className="bg-gradient-to-br from-purple-50 to-cyan-50 rounded-2xl p-8 mb-8">
              <h2 className="text-3xl font-bold text-gray-900 mb-6 text-center">
                üß† {t('llmC.howItWorks.title')}
              </h2>
              <div className="text-center mb-8">
                <span className="text-xl font-semibold bg-gradient-to-r from-purple-600 to-cyan-500 bg-clip-text text-transparent">
                  {t('llmC.howItWorks.subtitle')} üöÄ
                </span>
              </div>
              <p className="text-lg text-gray-700 leading-relaxed text-center">
                {t('llmC.howItWorks.description')}
              </p>
            </div>

            <div className="space-y-8">
              {/* Arquitectura */}
              <div className="bg-white rounded-xl shadow-lg p-8">
                <h3 className="text-2xl font-bold text-gray-900 mb-6 text-center">
                  ‚ö° {t('llmC.howItWorks.architecture.title')}
                </h3>
                
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                  <div className="space-y-4">
                    <div className="flex items-start space-x-4 p-4 bg-purple-50 rounded-lg">
                      <span className="claude-badge">Claude</span>
                      <div>
                        <h4 className="font-semibold text-gray-900">Director y Participante Activo</h4>
                        <p className="text-sm text-gray-700">Se asigna un rol estrat√©gico, participa en la primera ronda de respuestas, supervisa y consolida con formato visual enriquecido</p>
                      </div>
                    </div>
                    
                    <div className="flex items-start space-x-4 p-4 bg-green-50 rounded-lg">
                      <span className="openai-badge">GPT-4</span>
                      <div>
                        <h4 className="font-semibold text-gray-900">Analista Profundo</h4>
                        <p className="text-sm text-gray-700">Procesamiento avanzado con memoria conversacional completa</p>
                      </div>
                    </div>
                  </div>
                  
                  <div className="space-y-4">
                    <div className="flex items-start space-x-4 p-4 bg-blue-50 rounded-lg">
                      <span className="gemini-badge">Gemini</span>
                      <div>
                        <h4 className="font-semibold text-gray-900">Motor de Innovaci√≥n + Docs</h4>
                        <p className="text-sm text-gray-700">Perspectivas creativas, contexto extendido y generaci√≥n autom√°tica de Google Docs estructurados</p>
                      </div>
                    </div>
                    
                    <div className="flex items-start space-x-4 p-4 bg-yellow-50 rounded-lg">
                      <span className="perplexity-badge">Perplexity</span>
                      <div>
                        <h4 className="font-semibold text-gray-900">Investigador en Tiempo Real</h4>
                        <p className="text-sm text-gray-700">Acceso a informaci√≥n actualizada y verificaci√≥n de datos</p>
                      </div>
                    </div>
                  </div>
                </div>
              </div>

              {/* Innovaciones Tecnol√≥gicas */}
              <div className="bg-gradient-to-r from-gray-900 to-gray-800 text-white rounded-xl p-8">
                <h3 className="text-2xl font-bold mb-6 text-center">
                  üöÄ Innovaciones Tecnol√≥gicas Exclusivas
                </h3>
                
                <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
                  <div className="bg-white/10 backdrop-blur-sm rounded-lg p-4">
                    <h4 className="font-semibold mb-2">üé≠ Auto-Asignaci√≥n Inteligente</h4>
                    <p className="text-sm">Claude se asigna un rol estrat√©gico a s√≠ mismo y distribuye roles espec√≠ficos a cada LLM seg√∫n fortalezas y tipo de consulta.</p>
                  </div>
                  <div className="bg-white/10 backdrop-blur-sm rounded-lg p-4">
                    <h4 className="font-semibold mb-2">‚ö° Procesamiento Paralelo</h4>
                    <p className="text-sm">Consultas simult√°neas a todos los LLMs disponibles para m√°xima velocidad.</p>
                  </div>
                  <div className="bg-white/10 backdrop-blur-sm rounded-lg p-4">
                    <h4 className="font-semibold mb-2">üéØ Anti-Alucinaci√≥n</h4>
                    <p className="text-sm">Claude verifica consistencia entre respuestas y elimina informaci√≥n contradictoria.</p>
                  </div>
                  <div className="bg-white/10 backdrop-blur-sm rounded-lg p-4">
                    <h4 className="font-semibold mb-2">üé® Formato Visual</h4>
                    <p className="text-sm">Respuestas con tablas, l√≠neas, emojis tem√°ticos, bloques destacados y estructura jer√°rquica clara.</p>
                  </div>
                </div>
              </div>

              {/* Casos de Uso */}
              <div className="bg-white rounded-xl shadow-lg p-8">
                <h3 className="text-2xl font-bold text-gray-900 mb-6 text-center">
                  üí° Casos de Uso Perfectos
                </h3>
                
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                  <div className="space-y-3">
                    <h4 className="font-semibold text-purple-800">üî¨ Investigaci√≥n Compleja</h4>
                    <p className="text-sm text-gray-700">Combina datos actuales de Perplexity, an√°lisis profundo de GPT-4, creatividad de Gemini, supervisi√≥n de Claude</p>
                  </div>
                  <div className="space-y-3">
                    <h4 className="font-semibold text-blue-800">üíº Decisiones Empresariales</h4>
                    <p className="text-sm text-gray-700">M√∫ltiples perspectivas consolidadas en una recomendaci√≥n final verificada</p>
                  </div>
                  <div className="space-y-3">
                    <h4 className="font-semibold text-green-800">üé® Proyectos Creativos</h4>
                    <p className="text-sm text-gray-700">Innovaci√≥n de Gemini, refinamiento de GPT-4, investigaci√≥n de Perplexity, s√≠ntesis de Claude</p>
                  </div>
                  <div className="space-y-3">
                    <h4 className="font-semibold text-orange-800">üìö An√°lisis Acad√©mico</h4>
                    <p className="text-sm text-gray-700">Rigor cient√≠fico con m√∫ltiples enfoques metodol√≥gicos y verificaci√≥n cruzada</p>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </>
  );
}